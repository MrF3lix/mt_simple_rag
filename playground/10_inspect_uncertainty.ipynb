{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6d7ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from omegaconf import OmegaConf\n",
    "from lib.uncertainty import Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a815a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS = [\n",
    "    '2026-01-20_11-18'\n",
    "]\n",
    "\n",
    "strategy = {\n",
    "    'oracle': 'Oracle',\n",
    "    'random': 'Random',\n",
    "    'similar': 'Similar',\n",
    "    'dense': 'Dense'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8100a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = EXPERIMENTS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c8c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = {}\n",
    "\n",
    "for experiment in EXPERIMENTS:\n",
    "    cfg = OmegaConf.load(f'../results/{experiment}/config.yaml')\n",
    "    results = pd.read_json(f'../results/{experiment}/results.json')\n",
    "    results['correct_query'] = True\n",
    "    results['retriever_strategy'] = cfg.retriever.strategy\n",
    "\n",
    "    results_all[cfg.retriever.strategy] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9a8e2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Retriever Strategy</th>\n",
       "            <th>Query</th>\n",
       "            <th>Retreiver</th>\n",
       "            <th>Generator</th>\n",
       "            <th>Rows</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Similar</td>\n",
       "            <td>91.67% ± 7.6878%</td>\n",
       "            <td>11.77% ± 8.3568%</td>\n",
       "            <td>77.92% ± 10.1035%</td>\n",
       "            <td>10</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+--------------------+------------------+------------------+-------------------+------+\n",
       "| Retriever Strategy |      Query       |    Retreiver     |     Generator     | Rows |\n",
       "+--------------------+------------------+------------------+-------------------+------+\n",
       "|      Similar       | 91.67% ± 7.6878% | 11.77% ± 8.3568% | 77.92% ± 10.1035% |  10  |\n",
       "+--------------------+------------------+------------------+-------------------+------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "simulate = Simulate(cfg)\n",
    "\n",
    "t = PrettyTable(field_names=['Retriever Strategy', 'Query', 'Retreiver', 'Generator', 'Rows'])\n",
    "\n",
    "for experiment, results in results_all.items():\n",
    "    success_rates = simulate.compute_uncertainty(results)\n",
    "\n",
    "    t.add_row([\n",
    "        strategy[experiment],\n",
    "        f\"{success_rates['q']['mean']:.2%} ± {success_rates['q']['std']:.4%}\",\n",
    "        f\"{success_rates['r']['mean']:.2%} ± {success_rates['r']['std']:.4%}\",\n",
    "        f\"{success_rates['g']['mean']:.2%} ± {success_rates['g']['std']:.4%}\",\n",
    "        len(results)\n",
    "    ])\n",
    "\n",
    "\n",
    "t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "06-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
